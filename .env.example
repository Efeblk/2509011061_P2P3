# FalkorDB Configuration
FALKORDB_HOST=localhost
FALKORDB_PORT=6379
FALKORDB_PASSWORD=
FALKORDB_DB=0
FALKORDB_GRAPH_NAME=eventgraph

# Google Gemini API (Optional - Required only if AI_LOCAL=gemini)
GEMINI_API_KEY=your_gemini_api_key_here
GEMINI_MODEL=gemini-1.5-flash

# Scraping Configuration
SCRAPY_USER_AGENT=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36
# Scraping Performance Settings:
#   - Conservative (avoid bans):  SCRAPY_CONCURRENT_REQUESTS=16, SCRAPY_DOWNLOAD_DELAY=1
#   - Balanced:                   SCRAPY_CONCURRENT_REQUESTS=64, SCRAPY_DOWNLOAD_DELAY=0.5
#   - Aggressive (max speed):     SCRAPY_CONCURRENT_REQUESTS=256, SCRAPY_DOWNLOAD_DELAY=0
SCRAPY_CONCURRENT_REQUESTS=256   # Number of parallel requests (default: 256)
SCRAPY_DOWNLOAD_DELAY=0          # Delay between requests in seconds (default: 0)
PLAYWRIGHT_HEADLESS=true         # Run browser in headless mode (default: true)
PLAYWRIGHT_TIMEOUT=60000         # Page load timeout in milliseconds (default: 60000 = 60s)

# Application Settings
LOG_LEVEL=INFO
LOG_FILE=logs/eventgraph.log
ENVIRONMENT=development

# AI Analysis Settings
AI_LOCAL=ollama            # Default: "ollama" (Local Privacy). Optional: "gemini"
AI_MODEL_FAST=gemini-2.5-flash
AI_MODEL_REASONING=gemini-2.5-pro
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3.2
OLLAMA_MODEL_EMBEDDING=mxbai-embed-large
LOCAL_AI_REASONING=mistral-nemo

# Ollama Timeout Configuration (in seconds)
OLLAMA_HEALTH_TIMEOUT=5         # Health check timeout (default: 5)
OLLAMA_EMBED_TIMEOUT=30         # Embedding generation timeout (default: 30)
OLLAMA_GENERATE_TIMEOUT=120     # Text generation timeout (default: 120)
OLLAMA_CONTEXT_SIZE=2048        # LLM context window size in tokens (default: 2048, recommended 4096+ for 4070 Super)

# AI Processing Configuration
AI_BATCH_SIZE=10
AI_RATE_LIMIT_DELAY=1        # Delay between API calls (seconds)
AI_MAX_RETRIES=3
AI_CACHE_ENABLED=true
AI_ENABLE_EMBEDDINGS=false   # Enable vector embeddings (requires more resources)

# Concurrency Settings (Hardware-dependent)
# Adjust based on your CPU/RAM:
#   - Low-end (4GB RAM, 2 cores):  AI_CONCURRENCY=2
#   - Mid-range (8GB RAM, 4 cores): AI_CONCURRENCY=4
#   - High-end (16GB+ RAM, 8+ cores): AI_CONCURRENCY=8
# Higher = faster but more memory usage. Start low and increase if stable.
AI_CONCURRENCY=8

# Data Pipeline Settings
ENABLE_AI_ENRICHMENT=true
ENABLE_DUPLICATE_DETECTION=true
MIN_EVENT_PRICE=0
MAX_EVENT_PRICE=10000
